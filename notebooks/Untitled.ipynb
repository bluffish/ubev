{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f1bbf3-7f72-4263-955c-ed236ed1675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "gpu_ok = False\n",
    "if torch.cuda.is_available():\n",
    "    device_cap = torch.cuda.get_device_capability()\n",
    "    if device_cap in ((7, 0), (8, 0), (9, 0)):\n",
    "        gpu_ok = True\n",
    "\n",
    "if not gpu_ok:\n",
    "    warnings.warn(\n",
    "        \"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower \"\n",
    "        \"than expected.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d5073c-cb81-438a-9ed2-c414c8d918cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25be5cf6-7138-470f-bb49-1c0c317403b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7872e+00,  1.9614e+00,  9.0110e-04, -2.9500e-01,  7.7799e-01,\n",
      "          3.5593e-02, -1.3396e-02,  6.4578e-01, -1.2947e-01,  1.8579e+00],\n",
      "        [ 1.6040e+00,  1.8856e+00,  1.2606e+00,  1.7045e+00,  2.5772e-01,\n",
      "          7.4184e-01,  2.9223e-01, -3.8714e-01,  1.8560e+00,  3.5174e-01],\n",
      "        [-1.0209e+00,  2.4348e-02, -1.2797e-01,  1.8819e+00, -4.7803e-01,\n",
      "          9.3266e-01,  1.3870e+00,  1.1974e+00, -2.0989e-01,  1.6325e+00],\n",
      "        [ 8.4868e-01, -3.9857e-03,  8.0966e-01,  1.3976e+00,  1.2699e+00,\n",
      "         -4.5516e-01,  4.0862e-01,  5.2027e-01,  3.0611e-02,  6.7047e-01],\n",
      "        [-1.8843e+00,  1.9921e-01,  8.6538e-01,  7.9285e-01,  5.3565e-01,\n",
      "         -8.6505e-01,  7.4809e-01,  1.1497e+00, -8.3933e-03, -2.2558e-01],\n",
      "        [ 1.4868e+00, -8.5710e-02,  1.7295e+00,  1.5299e+00,  3.6676e-01,\n",
      "          9.1303e-01,  1.6716e+00,  1.4785e+00,  9.4002e-01,  6.5890e-01],\n",
      "        [ 1.7643e-01, -1.6536e-01,  9.6033e-01,  9.1788e-01,  1.0181e+00,\n",
      "          1.8507e+00,  1.0062e+00, -1.3371e-02,  4.3668e-01,  1.6076e+00],\n",
      "        [ 1.7384e-01,  1.7758e+00,  1.5920e+00,  2.1623e-02,  2.3669e-01,\n",
      "          1.2626e+00,  1.5897e+00,  1.7880e+00,  8.8004e-01,  7.7950e-01],\n",
      "        [ 5.2918e-01,  1.3682e+00,  2.5659e-01, -6.9384e-02,  1.3175e+00,\n",
      "          2.0487e-01,  1.9154e-01,  2.6372e-01,  1.2743e+00, -2.8180e-01],\n",
      "        [ 1.1457e+00,  1.1921e+00, -3.2439e-01,  8.1118e-02,  1.8782e+00,\n",
      "          8.2356e-01,  1.5285e+00,  1.4736e+00,  1.7316e-01,  1.0287e+00]])\n"
     ]
    }
   ],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5537e1a-5b7a-45cb-9ff3-aada2510be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, 0.0078, -0.0000, 0.1264, -0.0000, -0.0000, 0.1965, 1.0125, -0.0000,\n",
      "         0.0904],\n",
      "        [0.5082, 0.2965, -0.0000, 1.0539, -0.0000, 0.3981, -0.0000, 0.0936, -0.0000,\n",
      "         -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, 0.5585, 0.4620, 0.1551, 0.5080, -0.0000,\n",
      "         -0.0000],\n",
      "        [-0.0000, -0.0000, 0.2071, -0.0000, 1.1365, 0.4965, 0.5573, -0.0000, -0.0000,\n",
      "         -0.0000],\n",
      "        [-0.0000, 0.2231, -0.0000, 0.4177, -0.0000, 0.3016, -0.0000, 0.3646, -0.0000,\n",
      "         0.4215],\n",
      "        [-0.0000, 0.6417, -0.0000, 0.7434, 0.1864, 0.4046, -0.0000, -0.0000, 0.8087,\n",
      "         0.0656],\n",
      "        [0.0594, 0.5815, 0.4926, -0.0000, -0.0000, -0.0000, 0.3768, -0.0000, -0.0000,\n",
      "         -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, 1.3516, 1.1902, 0.4950, -0.0000, -0.0000,\n",
      "         0.3907],\n",
      "        [0.3714, -0.0000, -0.0000, -0.0000, 0.0324, 0.6633, -0.0000, 0.3417, -0.0000,\n",
      "         0.7288],\n",
      "        [0.0350, -0.0000, 0.4155, 0.6461, -0.0000, 0.1019, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.lin(x))\n",
    "\n",
    "mod = MyModule()\n",
    "opt_mod = torch.compile(mod)\n",
    "print(opt_mod(torch.randn(10, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863867b5-adac-4ac5-801c-dfd9e7e18ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is\n",
    "# batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d10a6c-65a0-4854-9c1c-e5f4365db276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.021341184616088867\n",
      "compile: 60.21555078125\n"
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "\n",
    "# Reset since we are using a different mode.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = generate_data(16)[0]\n",
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ca47f0-acd3-419a-9721-8dba3cd0c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager eval time 0: 0.027048959732055664\n",
      "eager eval time 1: 0.018497535705566406\n",
      "eager eval time 2: 0.016726015090942382\n",
      "eager eval time 3: 0.01577676773071289\n",
      "eager eval time 4: 0.01558835220336914\n",
      "eager eval time 5: 0.015185919761657715\n",
      "eager eval time 6: 0.015246335983276366\n",
      "eager eval time 7: 0.015119359970092774\n",
      "eager eval time 8: 0.015210495948791505\n",
      "eager eval time 9: 0.018497535705566406\n",
      "~~~~~~~~~~\n",
      "compile eval time 0: 1.0827969970703124\n",
      "compile eval time 1: 0.005703680038452149\n",
      "compile eval time 2: 0.005573631763458252\n",
      "compile eval time 3: 0.005536767959594726\n",
      "compile eval time 4: 0.005467135906219483\n",
      "compile eval time 5: 0.0054609918594360355\n",
      "compile eval time 6: 0.005463039875030518\n",
      "compile eval time 7: 0.0054579200744628905\n",
      "compile eval time 8: 0.005453824043273926\n",
      "compile eval time 9: 0.005475327968597412\n",
      "~~~~~~~~~~\n",
      "(eval) eager median: 0.015682559967041015, compile median: 0.005471231937408448, speedup: 2.8663672362004373x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, eager_time = timed(lambda: model(inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager eval time {i}: {eager_time}\")\n",
    "\n",
    "print(\"~\" * 10)\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, compile_time = timed(lambda: model_opt(inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile eval time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "import numpy as np\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4992beb0-6be2-4af7-958e-5dd4e740791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager train time 0: 0.5032314758300781\n",
      "eager train time 1: 0.06248550415039063\n",
      "eager train time 2: 0.05783039855957031\n",
      "eager train time 3: 0.06603059387207032\n",
      "eager train time 4: 0.05302374267578125\n",
      "eager train time 5: 0.052890625\n",
      "eager train time 6: 0.05248716735839844\n",
      "eager train time 7: 0.060796928405761716\n",
      "eager train time 8: 0.059061248779296874\n",
      "eager train time 9: 0.05958553695678711\n",
      "~~~~~~~~~~\n",
      "compile train time 0: 172.408875\n",
      "compile train time 1: 5.86939306640625\n",
      "compile train time 2: 0.05554687881469727\n",
      "compile train time 3: 0.0372305908203125\n",
      "compile train time 4: 0.038247425079345705\n",
      "compile train time 5: 0.04015513610839844\n",
      "compile train time 6: 0.042434558868408204\n",
      "compile train time 7: 0.03907174301147461\n",
      "compile train time 8: 0.04237823867797851\n",
      "compile train time 9: 0.043717632293701174\n",
      "~~~~~~~~~~\n",
      "(train) eager median: 0.05932339286804199, compile median: 0.042406398773193354, speedup: 1.3989255061559833x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train(mod, data):\n",
    "    opt.zero_grad(True)\n",
    "    pred = mod(data[0])\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, data[1])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, eager_time = timed(lambda: train(model, inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager train time {i}: {eager_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_opt = torch.compile(train, mode=\"reduce-overhead\")\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, compile_time = timed(lambda: train_opt(model, inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile train time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(train) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b8f4-99bd-42b1-a7aa-8af85d5ee879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d259a2-185d-43fc-b89f-67a4c502b7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd492a-bcb6-48c5-a4af-2eb47acba3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubev",
   "language": "python",
   "name": "ubev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
